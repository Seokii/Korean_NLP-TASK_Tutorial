{
  "passage_id": "PCY_201809200441135201_30",
  "metadata": {
    "doc_id": "PCY_201809200441135201",
    "doc_type": "도서",
    "doc_name": "인공지능 대응에 있어 형사법 이론의 한계",
    "author": "이원상",
    "publisher": "대검찰청",
    "published_year": "2018",
    "kdc_label": "법무및검찰",
    "kdc_code": "300"
  },
  "chapter": null,
  "passage": "둘째로, 인공지능 소유 및 관리자가 인공지능에게 명령하여 범죄를 저지른 경우를 살펴보자. 이 경우는 간접정범 이론이 적용될 가능성이 있다. 예를 들어, 인공지능 로봇 소유자가 인공지능 로봇에게 독약이 든 물을 영양제라고 속이고 피해자에게 가져다 주도록 한 경우 소유자는 고의 없는 도구를 사용하여 간접 정범으로 처벌 된다고도 할 수 있다. 아시모프 원칙에 따르면 인공지능 로봇은 피해자를 해하는 것을 몰랐기 때문에 제2원칙을 충실히 수행한 것이다. 만일 독약이라는 것을 알았다면 제1원칙에 따라 인공지능 로봇은 독약이 든 물을 피해자에게 가져다주지 않았을 것이다. 그에 반해 만일 로봇이 소유자 및 관리자 모르게 해당 범죄를 저지른 경우라면, 소유자 및 관리자는 자신이 인공지능 로봇에 대한 관리ㆍ감독을 소홀히 하지 않았다는 것을 입증하게 되면 책임을 면할 수 있을 것이다. 그러나 인공지능 로봇이 만일 자신의 행위가 인간에게 해를 끼치는 것을 알면서도 범죄행위를 했다면 로봇에게도 형사책임을 물을 수 있을 것이다. 하지만 그조차 없게 되면 적어도 형사처벌은 할 수 없을 것이며, 보험법의 문제로 해결되어야 할 것이다. 실제로 최근 미국에서 운전자가 탑승하여 자율주행 운행을 시험하던 우버(Uber)의 자율주행 자동차가 행인을 치어 숨지게 한 사건이 있었는데, 그 사건에 대한 미국의 판단이 나오면 좀 더 명확해질 수도 있을 것이다.",
  "summary": "인공지능 소유 혹은 관리자가 인공지능에게 범죄를 명령할 경우 간접정법 이론이 적용될 수 있다. 소유자가 인공지능에게 범죄를 명령, 인공지능은 모를 경우 소유자가 간접 정범 처벌을 받는다. 또다른 경우 인공지능이 소유자 모르게 범죄를 저지른다면 로봇에게 형사처벌 및 보험법으로 문제를 해결하며 소유자는 책임을 받지 않을 수 있다."
}