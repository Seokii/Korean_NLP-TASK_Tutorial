{
  "passage_id": "PCY_201611040300596511_69",
  "metadata": {
    "doc_id": "PCY_201611040300596511",
    "doc_type": "도서",
    "doc_name": "스마트컴퓨팅과 사용자행태 간의 상호작용의 미래 변화전망 연구",
    "author": null,
    "publisher": "과학기술정책연구원",
    "published_year": "2015",
    "kdc_label": "과학기술진흥",
    "kdc_code": "500"
  },
  "chapter": null,
  "passage": "대부분의 연구자들은 가속도 센서, 원심력 센서, 심박 센서 등 스마트폰 내장 센 서나 웨어러블 센서를 주로 사용해 연구를 진행했는데, 최근에는 사용자 시점의 영상 이미지를 이용한 행동 인식 연구도 등장하고 있다. Castro 등(2015)은 스마트폰을 목걸이 형태로 착용하고 사용자 관점에서 6개월간 약 4만 장의 사진을 찍은 후, 이를 19개 활동 중 하나로 정확히 분류할 수 있는지를 실험하였다. 나선형신경망 (Convolutional Neural Network : CNN)이라는 딥러닝 방법의 하나를 사용해 이미 지를 분류함과 동시에 상황맥락 요소로서 시간(요일과 시각) 변수를 같이 활용하여 그 시점의 사용자 행동을 예측하였다. 이미지와 상황맥락을 동시에 고려함으로써 현재 사용자가 수행하는 일상 행동의 예측 정확도가 83%에 달하였다.",
  "summary": "최근 연구자들은 사용자 시점의 영상 이미지를 이용한 행동 인식연구를 진행하였다.  실험결과는 나선현신경망이라는 딥러닝을 통해 사용자의 일상행동의 예측 정확도가 83%에 달하는 수준까지 왔다."
}