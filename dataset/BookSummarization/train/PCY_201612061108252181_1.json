{
  "passage_id": "PCY_201612061108252181_1",
  "metadata": {
    "doc_id": "PCY_201612061108252181",
    "doc_type": "도서",
    "doc_name": "인공지능 시대의 법적∙윤리적 쟁점",
    "author": null,
    "publisher": "과학기술정책연구원",
    "published_year": "2016",
    "kdc_label": "과학기술진흥",
    "kdc_code": "500"
  },
  "chapter": null,
  "passage": "일부 윤리학자들과 과학자들은 장기적으로 인공지능이 인류의 존속을 위협할 수 있다고 경고하고 있다. 2015년 5월 <Nature>에 게재된 ‘로봇공학: 인공지능의 윤리’는 LAWS(lethal autonomous weapon systems)를 우려하는 인공지능 선구자 스튜어트 러셀(Stuart Russell)의 주장을 담고 있다. UN 특정재래식 무기의 사용금지 및 제한에 관한 협약(CCW)은 LAWS를 회의 의제로 삼고 있다. 나아가 휴먼라이트워치(HRW) 등이 포함된 단체 ‘스톱킬러로봇’은 사전에 설정된 기준에 따라 목표물을 찾아내 공격하는 살상용 로봇의 개발과 배치·운용에 제동을 걸 수 있는 수단으로 국제 규제를 마련해야 한다고 주장한다. 로봇이 화재 진압용, 재난 구조용으로는 이용될 수 있지만 비용 대비 효율성과 산업적 유용성만을 중시하여 로봇 인공지능이 군사적 대량살상 목적으로 사용된다면 인류의 비극이라는 것이다. 자동적으로 살상을 하도록 프로그램된 킬러 로봇이 전장을 누비는 문제는 인권 침해 소지가 있으므로 적절한 시점에서 국제 규범이 성립될 확률이 크지만 그 우려를 인공지능 연구분야 전체로 확대하는 것은 무리가 있다.",
  "summary": "일부 학자들은 장기적으로 인공지능이 인류 존속을 위협할 가능성을 경고하고 있다. 대량살상을 목적으로 설계된 킬러 로봇이 가져올 인권 침해 소지를 경고하는 것이지만, 이를 인공지능 연구분야 전체의 문제로 확대하는 것은 무리이다."
}