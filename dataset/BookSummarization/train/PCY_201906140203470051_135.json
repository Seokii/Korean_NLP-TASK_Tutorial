{
  "passage_id": "PCY_201906140203470051_135",
  "metadata": {
    "doc_id": "PCY_201906140203470051",
    "doc_type": "도서",
    "doc_name": "4차 산업혁명 시대에서 정보인권 보호를 위한 실태조사",
    "author": null,
    "publisher": "국가인권위원회",
    "published_year": "2018",
    "kdc_label": "산업진흥·고도화",
    "kdc_code": "300"
  },
  "chapter": null,
  "passage": "영국 정보보호감독관(Information Commissioner's Office, ICO)은 2016년 <빅데이터, 인공지능, 머신러닝과 개인정보보호>라는 제목의 보고서를 발간하였다. ICO는 이 보고서에서 영국 및 유럽연합 법제도에서 보장하는 개인정보 보호 원칙을 개괄하면서 빅데이터, 인공지능 및 머신러닝 환경에 적용되는 정보인권 규범을 제시하고자 하였다. ICO는 우선 인공지능, 머신러닝 등 신기술의 발전을 가능하게 한 연료로서 빅데이터가 상당부분 개인정보로 구성된다는 점을 지적하였다. 그런데 빅데이터는 △알고리즘의 사용, △처리의 불투명성, △‘모든 데이터’를 수집하는 경향, △데이터의 목적 외 사용(repurposing), △새 유형의 데이터 사용 등의 특성으로 개인의 권리에 미치는 영향이 지대하다. 예를 들어, 자동차보험료 온라인 견적양식, 피트니스 트래커의 달리기 통계, 지역쇼핑센터 센서, 소셜미디어 게시물 등 방대하고 상이한 데이터세트로 구성되는데 이 데이터세트는 개인에 대한 정보를 담고 있다(ICO, 2017: 9~13). 공정성 원칙에서 보았을 때, 데이터세트에서 추출한 정보를 토대로 정보주체에 대해 결정을 내리거나 정보주체의 개인적 선호·행동·태도를 분석·예상하는 빅데이터 프로파일링(profiling) 분석은 개인에게 강압적인 효과를 미칠 수 있다. 예를 들어 어떤 맞춤광고는 인종을 토대로 사용자를 차별하는 프로파일링 처리에 기반했을 수 있으며, 특정 그룹의 저조한 상환기록을 토대로 유사한 다른 그룹의 신용한도가 낮아질 수 있다. 그럼에도 머신러닝 같은 빅데이터 분석법의 복잡성은 정보주체가 자신의 개인정보 처리에 대해 보장받아야 하는 투명성의 원칙을 오히려 위협한다(ICO, 2017: 19~28). ICO는 빅데이터가 그 구동 과정에 개인의 권리를 반영하고 결과 또한 정보주체의 기대를 벗어나지 않았을 때, 그 사회적 혜택 또한 널리 느껴질 수 있을 것이라고 지적하였다.",
  "summary": "ICO의  <빅데이터, 인공지능, 머신러닝과 개인정보보호> 보고서는 영국 및 유럽연합 법 제도에서 보장하는 개인 정보 보호 원칙을 개괄하면서 빅데이터, 인공지능 및 머신러닝 환경에 적용되는 정보인권 규범을 제시하였다. 머신러닝 같은 빅데이터 분석법의 복잡성은 정보주체가 보장받아야 하는 개인 정보 처리의 투명성의 원칙을 위협한다고 지적하며 ICO는 빅데이터가 그 구동 과정에 개인의 권리를 반영하고 결과 또한 정보주체의 기대를 벗어나지 않았을 때, 그 사회적 혜택 또한 널리 느껴질 수 있을 것이라고 지적하였다."
}