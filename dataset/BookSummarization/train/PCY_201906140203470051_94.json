{
  "passage_id": "PCY_201906140203470051_94",
  "metadata": {
    "doc_id": "PCY_201906140203470051",
    "doc_type": "도서",
    "doc_name": "4차 산업혁명 시대에서 정보인권 보호를 위한 실태조사",
    "author": null,
    "publisher": "국가인권위원회",
    "published_year": "2018",
    "kdc_label": "산업진흥·고도화",
    "kdc_code": "300"
  },
  "chapter": null,
  "passage": "세계 최대 전자상거래 기업 아마존은 2014년부터 인공지능 채용 시스템을 개발해오다 알고리즘에서 여성 차별적 인식이 드러나자 폐기했다. 아마존은 영국 스코틀랜드 에든버러에 엔지니어링팀을 꾸리고 AI 채용 프로그램을 개발해왔다. 500대의 컴퓨터가 구직 희망자의 지원서를 약 5만 개 키워드로 분석해 1개에서 5개까지의 별점을 매기는 프로그램이다. 그러나 개발이 1년쯤 진행되었을 무렵 아마존 자체 AI 채용시스템이 여성 지원자를 선호하지 않는다는 사실이 드러났다. AI가 10년간의 아마존 지원자 데이터를 분석한 결과 남성 지원자가 압도적으로 많았기 때문이다. 이 채용 프로그램은 이력서에 '여성'이라는 단어가 들어가거나 동아리 항목에 '여성 체스 클럽'이라는 문구가 들어간 지원자를 감점했으며, 여대를 나온 2명의 지원자 원서에도 불이익을 줬다. 성별에 대한 편향만이 문제가 아니었다. 키워드를 자체 분석하는 AI 채용 프로그램의 알고리즘 때문에 지원자의 기술이나 능력보다는 지원서에 쓴 능력과 관련 없는 단어들이 더 중요해졌다. 실제로 '실행했다(executed)' '데이터를 수집했다(captured)'는 단어를 지원서에 쓴 경우 좋은 평가를 받았다. 아마존은 인공지능의 시스템 개선에 나섰지만 공정성 확보에 실패했다고 판단해 지난해 초 AI 채용 프로그램을 자체 폐기했다.",
  "summary": "아마존은 인공지능 채용 시스템을 개발해왔으나 10년간의 아마존 지원자 데이터 내 남성 지원자의 비율이 압도적으로 높았기에 이와 같은 데이터와 알고리즘을 바탕으로 한 자체 AI 채용 시스템이 여성 지원자를 선호하지 않는다는 것을 확인했다. 아마존은 시스템 개선을 시도했으나 공정성 확보에 실패했다고 판단해 프로그램을 폐기했다."
}