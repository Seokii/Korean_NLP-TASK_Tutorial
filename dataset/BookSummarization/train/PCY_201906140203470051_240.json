{
  "passage_id": "PCY_201906140203470051_240",
  "metadata": {
    "doc_id": "PCY_201906140203470051",
    "doc_type": "도서",
    "doc_name": "4차 산업혁명 시대에서 정보인권 보호를 위한 실태조사",
    "author": null,
    "publisher": "국가인권위원회",
    "published_year": "2018",
    "kdc_label": "산업진흥·고도화",
    "kdc_code": "300"
  },
  "chapter": null,
  "passage": "또한 시스템 전반의 투명성이 보장될 필요가 있다. 가령, 인공지능 면접 프로그램의 분석 결과는 데이터 그 자체가 아니라 코딩된 연산 결과에 따른 것이기에 알고리즘을 명확하게 이해할 수 있도록 투명한 설명을 요구할 권리가 주어지지 않는다면 여전히 그것은 블랙박스로 남게 된다. 통제가 안 되는 데이터와 알고리즘은 데이터의 조작, 악용의 위험을 높이고 사회적 편견을 강화할 경향이 다분하다. 빅데이터 알고리즘의 자동화된 의사결정이 우리 삶에 깊숙이 파고드는 지금의 맥락에서 알고리즘이 어떻게 작동하는지에서부터, 아웃풋(자동화된 의사결정)이 어떻게 만들어지는지 까지 정보주체가 그 프로세스를 명확하게 이해할 수 있도록 돕는 장치가 필요하다.",
  "summary": "시스템 전반의 투명성이 보장돼야 한다. 통제 밖의 데이터와 알고리즘은 조작과 악용의 위험이 높고 사회적 편견을 높이게 된다. 정보주체가 빅데이터 알고리즘 프로세스를 이해할 수 있어야 한다."
}