{
  "passage_id": "PCY_201810220547101391_85",
  "metadata": {
    "doc_id": "PCY_201810220547101391",
    "doc_type": "도서",
    "doc_name": "4차 산업혁명 대응 법제 정비 연구 (Research on the Improvement of Legislative Systems in the Era of the 4th Industrial Revolution)",
    "author": "조성은, 이원태, 이시직",
    "publisher": "정보통신정책연구원,과학기술정보통신부,정보통신기술진흥센터",
    "published_year": "2018",
    "kdc_label": "과학기술연구",
    "kdc_code": "500"
  },
  "chapter": null,
  "passage": "이 보고서들은 데이터 기반의 결정이 사람의 주관이나 편견에서 벗어나 객관적이라는 믿음이 잘못되었을 수도 있음을 드러낸다. 즉, ‘데이터 근본주의’(data fundamentalism)에서 의도하지 않은 오류 가능성이 있을 수 있음을 지적한 것이다. 첫째, 사회적 차별의 고착화문제이다. 만약 빅데이터 혹은 인공지능 알고리즘에 투입된 데이터가 특정 계층만을 대상으로 한 것이라면, 데이터가 반영하지 못한, 그래서 결과에서 소외되는 또 다른 특정 계층 이 생기게 된다. 이런 식의 데이터 피드백이 반복되어 누적되면 사회적 차별이 고착화될 가능성이 높아진다. 그동안 특정 인종이나 특정 지역 거주민들에 대한 통계 결과가 사회 적 낙인으로 기능하였던 사례들을 떠올려도 된다. 최근 사례로는 포털 사이트의 알고리즘 에 기반한 검색 순위 및 기사 배열 이슈를 들 수 있다. 알고리즘 방식을 도입하였다는 것 은 인간의 개입을 가급적 배제하여 객관적인 데이터에 입각한 검색 순위 및 기사 배열의 순서를 의도한 것이다. 그러나 인터넷에 있는 데이터가 오랜 사회적 편견을 반영한 것이 라면, 이용자들의 검색 빈도 자체가 가치 편향을 담고 있다면 어떠한가. 그러한 문제가 제기되면서 데이터 기반의 인공지능 학습 과정을 거쳐 완성되어 가는 알고리즘이 이미 특정 편향을 내포하고 있을 가능성을 배제할 수 없는 상황을 맞이하게 되었다.",
  "summary": "데이터가 객관적이라고 믿는 데이터 근본주의는 사실 여러가지 문제점을 내포하고 있는데, 대표적으로 데이터에 반영된 자료가 특정한 집단만을 대상으로 하는 경우, 소외된 집단의 현실은 데이터로 나타나지 않는다는 점이 있다. "
}