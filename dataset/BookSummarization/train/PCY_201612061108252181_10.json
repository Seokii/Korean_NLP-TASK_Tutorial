{
  "passage_id": "PCY_201612061108252181_10",
  "metadata": {
    "doc_id": "PCY_201612061108252181",
    "doc_type": "도서",
    "doc_name": "인공지능 시대의 법적∙윤리적 쟁점",
    "author": null,
    "publisher": "과학기술정책연구원",
    "published_year": "2016",
    "kdc_label": "과학기술진흥",
    "kdc_code": "500"
  },
  "chapter": null,
  "passage": "물론 미래의 이야기겠지만 판매된 로봇이 소유주의 말을 따라서 사람을 치거나 물건을 파손하거나 악용되고 사고를 일으키는 등 문제가 발생했을 때 책임은 언제나 소유주가 지는 것인지 아니면 그 명령을 따르도록 알고리즘을 설계한 제작자가 지는지를 가리기 쉽지 않을 전망이다. 로봇이 불법행위에 사용되지 않도록 차라리 처음부터 로봇 자체가 인체를 해하거나 파괴적 행동의 명령은 거부하거나 윤리적 판단이 가능하도록 설계할 수도 있다. 제조사나 설계자의 선택에 따라서 로봇은 자율적으로 행동할 여지가 있는데 그렇다면 로봇의 인공지능 시스템을 도덕적 행위자(AMA)로 의제하고 로봇에게 책임을 물어야 할까? 그런데 로봇의 자율적 판단에 대한 책임을 로봇 스스로가 지도록 하려면 로봇의 기술이 어느 수준에 도달해야 할까? 이러한 의문은 2035년의 시카고를 배경으로 한 영화 <아이, 로봇>의 주제이기도 하다. 만일 로봇이 단지 기계적인 작업이 아니라 인간 고유의 영역에 들어와서 고도의 지적 작업이 필요한 일을 하게 된다면 그 인지적 판단의 수준이 높을 것으로 예견되는 데 이 경우도 로봇의 불법적 행동이나 부작위에 대하여는 수동적 기계라는 이유로 면책하여야 하는 것인가 등이 문제될 수 있다. 이러한 논의가 가능한 이유는 인공지능을 갖춘 로봇의 등장은 스스로의 판단 하에 움직이는 새로운 개체 또는 주체의 출현을 의미한다는 점을 다수가 수용하고 있고 사람들이 로봇을 기계 덩어리가 아니라 의인화된 대상으로 받아들이기 때문이다.",
  "summary": "로봇이 소유주의 말을 따라서 사람에게 해를 가하거나 악용될 경우 책임문제를 어떻게 해결할지 쉽지 않다. 애초에 윤리적 판단이 가능하도록 설계할 수도 있으나, 로봇이 고도의 지적 작업을 할 수 있을 정도로 지능화된다면 스스로 판단하에 움직이게 되기 때문에 기계가 아니라 의인화한 대상이 될 수도 있다. "
}