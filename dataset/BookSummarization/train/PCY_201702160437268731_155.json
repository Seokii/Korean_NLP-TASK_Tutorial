{
  "passage_id": "PCY_201702160437268731_155",
  "metadata": {
    "doc_id": "PCY_201702160437268731",
    "doc_type": "도서",
    "doc_name": "글로벌 기초연구정책 이슈 분석 및 플랫폼 구축 방안",
    "author": null,
    "publisher": "과학기술정책연구원",
    "published_year": "2016",
    "kdc_label": "과학기술연구",
    "kdc_code": "500"
  },
  "chapter": null,
  "passage": "글로벌 기초연구정책 정보 플랫폼이 사용자에게 정책정보를 지원하기까지의 프로세스는 국가별 기본 통계에서부터 연구 성과물을 설명하는 메타데이터 혹은 소셜 데이터에 이르기까지 다양한 형식의 외부 자료를 주기적으로 수집하는 것에서부터 시작된다. 그리고 수집한 자료를 추출기(extractor)로 보내 스트림(stream), 데이터베이스(database), 로그(log) 등의 자료형식에 따라 데이터를 추출한다. 이 데이터는 분석에 활용되기 전에 데이터를 관리하는 대규모 저장소인 데이터 호수(data lake)에 보관된다. 데이터 호수는 스프레드시트와 같이 고정된 필드에 저장된 정형(structured) 데이터, 웹문서와 같이 메타데이터를 포함하는 반정형(semi-structured) 데이터, 텍스트, 음성, 이미지와 같이 고정 필드에 저장되지 않은 데이터를 의미하는 비정형(unstructured) 데이터 등 다양한 유형의 데이터를 관리한다. 보관소 혹은 내부 데이터베이스에 저장된 데이터는 전처리(pre-processing)라는 가공과정을 거쳐야 분석에 활용될 수 있다. 잡음(noise)이 많이 포함된 채로 데이터가 분석에 활용된다면 의도하지 않은 결과를 생성하므로 전처리 과정은 분석 결과의 품질을 좌우한다. 전처리 과정에는 여러 데이터를 결합하는 통합(integration) 혹은 일관된 포맷으로 표현하는 서식화(formatting), 결측치와 모순된 데이터 등을 해결하는 데이터 정제(cleansing), 방대한 자료를 요약하는 집계(aggregation) 등이 포함된다. 정리된 데이터는 목적에 따라 다양한 분석방법이 적용되며 기술(descriptive)분석, 데이터 마이닝, 추천(recommendation) 알고리즘, 기계학습(machine learning) 등이 대표적인 예다. 이렇게 도출된 분석 결과는 내부 데이터베이스에 보관되고, 정책 전문가들의 해석이 덧붙여져 다양한 형태로 출판되는 과정을 거치게 된다.",
  "summary": "글로벌 기초연구정책 정보 플랫폼이 외부 자료를 추합하는 것부터 시작한다. 그리고 이런 자료를 데이터 호수에 보관한다. 그리고 데이터는 전처리 가공과정을 거치게 되낟. 정리된 데이터는 목적에 따라 분류되며, 분석 결과는 다양한 형태로 출판된다. "
}