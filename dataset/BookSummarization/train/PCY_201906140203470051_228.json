{
  "passage_id": "PCY_201906140203470051_228",
  "metadata": {
    "doc_id": "PCY_201906140203470051",
    "doc_type": "도서",
    "doc_name": "4차 산업혁명 시대에서 정보인권 보호를 위한 실태조사",
    "author": null,
    "publisher": "국가인권위원회",
    "published_year": "2018",
    "kdc_label": "산업진흥·고도화",
    "kdc_code": "300"
  },
  "chapter": null,
  "passage": "아실로마 인공지능 원칙, 일본 정보통신정책연구소의 <인공지능 개발원칙>, 유럽 개인정보보호감독관의 <빅데이터의 문제 해결에 관한 의견서(2015)>, 영국 정보보호감독관의 보고서, 국제 개인정보보호 감독기구 회의(ICDPPC)의 <인공지능 윤리 및 개인정보 보호에 대한 선언> 등 대부분의 연구자 및 공공기관은 인공지능 등 신기술에 대한 대응에 있어서 ‘투명성’의 중요성을 지적하고 있다. 사물인터넷의 확대로 서로 다른 기기나 시스템 사이에서 수많은 정보처리 과정이 수행되면서, 개인정보의 수집부터 처리까지 어떻게 작동되는지 정보주체가 인지하기 힘들고, 이에 따라 통제권이 무력화될 우려가 있다. 또한 인공지능 알고리즘의 경우 개발자들도 그 결과가 발생한 메커니즘을 파악하기 힘들다. 따라서 시스템의 투명성이 보장되지 않으면 오류의 발견뿐만 아니라 차별의 시정이나 정보주체의 권리 행사가 불가능하다. 인공지능 알고리즘에 대한 로직의 공개, 정보주체의 설명을 요구할 권리 보장, 사후에 설명, 감사, 검증이 가능한 방식의 설계 등 시스템의 투명성을 보장할 수 있는 방식의 제도적 장치가 필요하다. GDPR에서도 제5조 (a)에서 개인정보는 “정보주체에 대해 합법적으로, 공정하게, 투명한 방식으로 처리되어야(적법성, 공정성, 투명성)”함을 규정하고 있으며, 개인정보처리자의 신원 및 처리 목적 등을 정보주체에 고지하도록 하고 정보주체에 설명을 요구할 권리를 부여하는 등의 구체적인 규정을 두고 있다.",
  "summary": "대부분의 연구자 및 공공기관은 인공지능 등 신기술에 대한 시스템의  ‘투명성’의 중요성을 지적하고 있는데, 투명성이 보장되지 않으면 오류의 발견은 물론, 차별의 시정이나 정보주체의 권리 행사도 불가능하므로, 시스템의 투명성을 보장할 수 있는 방식의 제도적 장치가 필요하다."
}